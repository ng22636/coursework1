{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choice of Problem\n",
    "\n",
    "In this notebook, we explain our choice of problem, linking back what what we learned in Project 0. We will use what we have learnt in Project 0, taking into consideration the issues we faced and the things which worked well.\n",
    "\n",
    "**Table of Contents**\n",
    "- [1. Reflections and Links to Project 0](#1-reflections-and-links-to-project-0)\n",
    "- [2. Data Search](#2-data-search)\n",
    "    - [2.1. Data Sources](#21-data-sources)\n",
    "- [3. Datasets](#3-datasets)\n",
    "    - [3.1. Classification Problems](#31-classification-problems)\n",
    "    - [3.2. Kaggle Datasets](#32-kaggle-datasets)\n",
    "    - [3.3. UCI Datasets](#33-uci-datasets)\n",
    "    - [3.4. scikit-learn Datasets](#34-scikit-learn-datasets)\n",
    "- [4. Choice of Dataset](#4-choice-of-dataset)\n",
    "- [5. Conclusion](#5-conclusion)\n",
    "\n",
    "## 1. Reflections and Links to Project 0\n",
    "In Project 0, we used structured finance data as it was easy to find and provided opportunities to apply many different techniques. We investigated a classification problem, learning about challenges that it can involve, such as imbalanced data and missing data. This was interesting to us and we therefore chose a **classification problem** for Project 1. We chose not to analyse the same data, as we wanted to showcase our abilities to draw unique insights when the answers were not presented to us. We will instead draw upon the Kaggle notebooks we encountered and adapt our approach to our chosen problem. We believe that this will also help us grow and develop our skills further.\n",
    "\n",
    "We encountered an issue with the Kaggle dataset, as it was too large to upload to Github, and we did not have any other file hosting solution. We considered this issue in our data search for Project 1 and aimed to find data that was easy to import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Search\n",
    "\n",
    "### 2.1. Data Sources\n",
    "\n",
    "In Project 0, we diligently searched a variety of data sources to find datasets for Project 1. We found several interesting datasets that present unique challenges like imbalanced data, missing values, and outliers, making them excellent candidates for providing learning opportunities. In searching for sources for this project, I discovered additional sources, such as:\n",
    "- [Dataset List](https://www.datasetlist.com/): This contains several machine learning datasets, involving image classification, NLP and other techniques.\n",
    "- [QuantumStat Dataset Index](https://index.quantumstat.com/): This contained several NLP problems.\n",
    "\n",
    "These contained large datasets or required advanced techniques (such as natural language processing) and were not pursued further due to size or complexity. They are included for the reader's interest. Below are other additional sources we explored, which were more feasible for analysis:\n",
    "- [Serokell’s Blog on Best ML Datasets](https://serokell.io/blog/best-machine-learning-datasets): Accessible blog containing many sources of datasets such as **[Google Dataset Search](https://datasetsearch.research.google.com/)**.\n",
    "- [Scikit-learn Real-World Datasets](https://scikit-learn.org/1.5/datasets/real_world.html): This package provided real-world datasets which can easily be imported using the provided code.\n",
    "\n",
    "We also used other resources from Project 0, such as **[Kaggle](https://www.kaggle.com/datasets)** and the **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**. This provided us with a rich source of varied datasets. We present some interesting datasets in the next section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Datasets\n",
    "\n",
    "As described earlier, we chose to focus on a classification problem. We provide some datasets for classification below. The datasets we selected present a wide range of challenges, including missing data and imbalanced classes. This provides an excellent opportunity for testing various machine learning techniques.\n",
    "\n",
    "### 3.1 Classification Problems\n",
    "\n",
    "The datasets are grouped by source. Kaggle datasets can be downloaded and uploaded to Github or another file hosting solution if the file size permits. The UCI datasets can be loaded very easily by following the links provided and clicking the \"Import to Python\" button. This gives Python code to load the data. The sci-kit learn datasets can also be easily loaded using Python code given below.\n",
    "\n",
    "#### 3.2 Kaggle Datasets\n",
    "\n",
    "1. **Titanic Survival Dataset**\n",
    "   - **Description:** Predict passenger survival based on demographic data like age, gender, and class.\n",
    "   - **Challenges:** **Missing data** (especially age) and **imbalanced data** (fewer survivors).\n",
    "   - **Size:** 891 records with 12 features.\n",
    "   - **Use Case:** Survival prediction, historical data analysis.\n",
    "   - **Source:** [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)\n",
    "\n",
    "---\n",
    "\n",
    "2. **Loan Prediction Dataset**\n",
    "   - **Description:** Predict loan approval based on credit history, income, and other financial information.\n",
    "   - **Challenges:** **Missing data** and slightly **imbalanced** outcomes.\n",
    "   - **Size:** 615 records with 13 features, with a separate test set of about 300 records.\n",
    "   - **Use Case:** Financial decision-making.\n",
    "   - **Source:** [Loan Prediction Dataset](https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.3 UCI Datasets\n",
    "\n",
    "3. **Breast Cancer Dataset**\n",
    "   - **Description:** Predict whether a tumor is benign or malignant based on cell nuclei features.\n",
    "   - **Challenges:** Slightly **imbalanced dataset** (more benign than malignant cases).\n",
    "   - **Size:** 569 samples with 30 features.\n",
    "   - **Use Case:** Medical diagnosis.\n",
    "   - **Source:** [UCI Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
    "\n",
    "---\n",
    "\n",
    "4. **Adult Income Dataset (Census Data)**\n",
    "   - **Description:** Predict whether an individual's income exceeds $50,000 based on demographic features.\n",
    "   - **Challenges:** **Missing values** in some attributes like occupation, **imbalanced classes** (fewer high-income individuals).\n",
    "   - **Size:** 48,842 records with 14 features.\n",
    "   - **Use Case:** Social and economic analysis.\n",
    "   - **Source:** [UCI Adult Dataset](https://archive.ics.uci.edu/ml/datasets/adult)\n",
    "\n",
    "---\n",
    "\n",
    "5. **Drug Consumption Dataset**\n",
    "   - **Description:** Predict whether an individual consumes a drug based on personality traits and demographics.\n",
    "   - **Challenges:** **Imbalanced data** and potential ethical concerns.\n",
    "   - **Size:** 1,889 records with 12 features.\n",
    "   - **Use Case:** Behavioral studies, addiction research.\n",
    "   - **Source:** [UCI Drug Consumption Dataset](https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.4 scikit-learn Datasets\n",
    "\n",
    "6. **Forest Cover Type Dataset**\n",
    "   - **Description:** Classify forest cover type based on cartographic features like elevation and soil type.\n",
    "   - **Challenges:** **Imbalanced data** across forest types.\n",
    "   - **Size:** 581,012 records with 54 features.\n",
    "   - **Use Case:** Environmental monitoring, land management.\n",
    "   - **Method to Load:** `fetch_covtype()` (also available on [UCI ML Repository](https://archive.ics.uci.edu/dataset/31/covertype))\n",
    "\n",
    "---\n",
    "\n",
    "7. **Digits Dataset**\n",
    "   - **Description:** Handwritten digit images (0–9) with pixel values, used for classification.\n",
    "   - **Challenges:** Preprocessing steps like feature scaling and dimensionality reduction add complexity.\n",
    "   - **Size:** 1,797 records, each with 64 features (an 8x8 pixel image).\n",
    "   - **Use Case:** Optical character recognition (OCR), computer vision.\n",
    "   - **Method to Load:** `load_digits()`\n",
    "\n",
    "---\n",
    "\n",
    "8. **20 Newsgroups Dataset**\n",
    "   - **Description:** A text dataset for classification tasks, with the goal of classifying documents into one of 20 different newsgroups based on their content.\n",
    "   - **Size:** 18,000 posts from newsgroups.\n",
    "   - **Challenges:** Text classification and natural language processing (NLP).\n",
    "   - **Use Case:** Text mining and topic modeling.\n",
    "   - **Method to Load:** `fetch_20newsgroups()`\n",
    "\n",
    "---\n",
    "\n",
    "For more information and additional datasets, please visit Kaggle, the UCI Machine Learning Repository, or [scikit-learn's real-world datasets page](https://scikit-learn.org/1.5/datasets/real_world.html).\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Choice of Dataset \n",
    "\n",
    "The datasets which particularly stood out to us were the forest cover dataset and adult income dataset. These datasets present a variety of challenges and opportunities for applying classification and regression techniques. They are also excellent for testing advanced methods for handling imbalanced data (e.g., synthetic minority oversampling technique -- SMOTE), and for handling missing data (e.g., imputation).\n",
    "\n",
    "After an in-person meeting and online WhatsApp discussions, we settled on using the adult income dataset.\n",
    "\n",
    "# 5. Conclusion\n",
    "\n",
    "This document shows the thought process behind making our choice to analyse the adult income dataset. The next documents will describe the models we explored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
