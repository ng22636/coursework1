{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da8c43d-a755-4c71-bddf-71e5244f6646",
   "metadata": {},
   "source": [
    "# For Group Members\n",
    "\n",
    "## Data Split\n",
    "\n",
    "After doing EDA on the data, we saw that there were about twice as many males as females and that majority race was white. This prompted us to think about these questions:\n",
    "- How does the proportion of high income individuals vary across sex?\n",
    "- How does the proportion of high income individuals vary across race?\n",
    "\n",
    "At an in-person group meeting, we decided to focus on the first question. The `race` variable contained categories with very few observations in them, which would pose a challenge upon doing a test/train split. Hence, we will perform a test/train split, taking care to ensure that the distribution of the **sexes** in the test data is the same as in the overall data.\n",
    "\n",
    "The split is done in the following way. We ensure that the test data contains complete cases only. We do this by first removing the missing data from $X$ and $y$, and extracting test data stratified by sex. We then take the complement of this to obtain the training set. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "427a2870-efb7-47a1-9f22-b912ac0460fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fetch the Adult dataset from UCI ML repository\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# Note this takes up to 20 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5269cf29-aebd-4329-a7cd-2185aed8cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of data by sex: overall data (before split), training data, test data.\n",
      "Overall sex proportion:\n",
      " sex\n",
      "Male      0.668482\n",
      "Female    0.331518\n",
      "Name: proportion, dtype: float64\n",
      "Training set sex proportion:\n",
      " sex\n",
      "Male      0.666466\n",
      "Female    0.333534\n",
      "Name: proportion, dtype: float64\n",
      "Test set sex proportion:\n",
      " sex\n",
      "Male      0.677327\n",
      "Female    0.322673\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megar\\AppData\\Local\\Temp\\ipykernel_48216\\2915566502.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace('?', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Separate features and targets\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Replace '?' with NaN in X\n",
    "X.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Clean the target variable (income)\n",
    "y.loc[:, y.columns[0]] = y[y.columns[0]].replace({'<=50K.': '<=50K', '>50K.': '>50K'})\n",
    "\n",
    "# Ensure the split maintains the proportion of 'sex' in the test set\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=X['sex'], random_state=42\n",
    ")\n",
    "\n",
    "# Drop rows with missing data (NaN values) from X_test and ensure y_test is consistent\n",
    "X_test = X_test_raw.dropna()\n",
    "y_test = y_test_raw.loc[X_test.index]\n",
    "\n",
    "# Subtract X_test from the original dataset to get X_train\n",
    "X_train = X.drop(X_test.index)\n",
    "y_train = y.drop(y_test.index)\n",
    "\n",
    "# Display the proportion of 'sex' in the overall dataset, training, and test sets\n",
    "overall_sex_proportion = X['sex'].value_counts(normalize=True)\n",
    "train_sex_proportion = X_train['sex'].value_counts(normalize=True)\n",
    "test_sex_proportion = X_test['sex'].value_counts(normalize=True)\n",
    "\n",
    "# Print the proportions\n",
    "print(\"Proportion of data by sex: overall data (before split), training data, test data.\")\n",
    "print(\"Overall sex proportion:\\n\", overall_sex_proportion)\n",
    "print(\"Training set sex proportion:\\n\", train_sex_proportion)\n",
    "print(\"Test set sex proportion:\\n\", test_sex_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec1fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values in each feature (training set):\n",
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "dtype: int64\n",
      "\n",
      "Number of missing values in each feature (test set):\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in X_train and X_test\n",
    "missing_in_train = X_train.isna().sum()\n",
    "missing_in_test = X_test.isna().sum()\n",
    "\n",
    "# Count the total number of missing values in each dataset\n",
    "total_missing_train = X_train.isna().sum().sum()\n",
    "total_missing_test = X_test.isna().sum().sum()\n",
    "\n",
    "# Print the number of missing data in each set\n",
    "print(\"\\nNumber of missing values in each feature (training set):\")\n",
    "print(missing_in_train)\n",
    "\n",
    "print(\"\\nNumber of missing values in each feature (test set):\")\n",
    "print(missing_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d566dc",
   "metadata": {},
   "source": [
    "I write the data to csv files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f43a031-484d-462c-abeb-dd00ce016d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Datasets saved as '../data/X_train.csv', '../data/y_train.csv', '../data/X_test.csv', and '../data/y_test.csv' with index.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a 'data' directory in the parent directory if it doesn't exist\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "# Save X_train, y_train, X_test, and y_test to separate CSV files\n",
    "X_train.to_csv(\"../data/X_train.csv\", index=True)        # Save features of train set\n",
    "y_train.to_csv(\"../data/y_train.csv\", index=True)        # Save targets of train set\n",
    "X_test.to_csv(\"../data/X_test.csv\", index=True)          # Save features of test set\n",
    "y_test.to_csv(\"../data/y_test.csv\", index=True)          # Save targets of test set\n",
    "\n",
    "\"Datasets saved as '../data/X_train.csv', '../data/y_train.csv', '../data/X_test.csv', and '../data/y_test.csv' with index.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25abb09",
   "metadata": {},
   "source": [
    "You can use this code to load the data (and optionally check with the output to make sure it worked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac5589c9-31eb-4ead-91fd-c1c31c17f39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   age         workclass  fnlwgt  education  education-num  \\\n",
       " 0   39         State-gov   77516  Bachelors             13   \n",
       " 1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       " 2   38           Private  215646    HS-grad              9   \n",
       " 3   53           Private  234721       11th              7   \n",
       " 4   28           Private  338409  Bachelors             13   \n",
       " \n",
       "        marital-status         occupation   relationship   race     sex  \\\n",
       " 0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       " 1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       " 2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       " 3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       " 4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       " \n",
       "    capital-gain  capital-loss  hours-per-week native-country  \n",
       " 0          2174             0              40  United-States  \n",
       " 1             0             0              13  United-States  \n",
       " 2             0             0              40  United-States  \n",
       " 3             0             0              40  United-States  \n",
       " 4             0             0              40           Cuba  ,\n",
       "   income\n",
       " 0  <=50K\n",
       " 1  <=50K\n",
       " 2  <=50K\n",
       " 3  <=50K\n",
       " 4  <=50K,\n",
       "        age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       " 20156   18   Private  271935       HS-grad              9       Never-married   \n",
       " 28772   67   Private  160456          11th              7             Widowed   \n",
       " 1732    26   Private  314177       HS-grad              9       Never-married   \n",
       " 38871   31   Private  176711       HS-grad              9       Never-married   \n",
       " 27566   56   Private  134286  Some-college             10  Married-civ-spouse   \n",
       " \n",
       "               occupation   relationship   race     sex  capital-gain  \\\n",
       " 20156  Machine-op-inspct      Own-child  White  Female             0   \n",
       " 28772      Other-service  Not-in-family  White  Female             0   \n",
       " 1732               Sales  Not-in-family  Black    Male             0   \n",
       " 38871       Craft-repair  Not-in-family  White    Male             0   \n",
       " 27566    Exec-managerial        Husband  White    Male             0   \n",
       " \n",
       "        capital-loss  hours-per-week native-country  \n",
       " 20156             0              40  United-States  \n",
       " 28772             0              40  United-States  \n",
       " 1732              0              40  United-States  \n",
       " 38871             0              40  United-States  \n",
       " 27566             0              45  United-States  ,\n",
       "       income\n",
       " 20156  <=50K\n",
       " 28772  <=50K\n",
       " 1732   <=50K\n",
       " 38871  <=50K\n",
       " 27566  <=50K)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You can use this code to load it\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved datasets from the CSV files\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\", index_col=0)  # Use the first column as index\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", index_col=0)  # Use the first column as index\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\", index_col=0)    # Use the first column as index\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\", index_col=0)    # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the loaded datasets\n",
    "(X_train.head(), y_train.head(), X_test.head(), y_test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb401c7b-e3cf-4cec-a558-7c8a8fbbd708",
   "metadata": {},
   "source": [
    "# Checks\n",
    "\n",
    "I do some checks below to show that this is doing the right things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63da65a4-e6fc-4d03-a12c-9c6b2a4fd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_equal: True\n",
      "y_train_equal: True\n",
      "X_test_equal: True\n",
      "y_test_equal: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved datasets from the CSV files\n",
    "X_train_loaded = pd.read_csv(\"../data/X_train.csv\", index_col=0)  # Use the first column as index\n",
    "y_train_loaded = pd.read_csv(\"../data/y_train.csv\", index_col=0)  # Use the first column as index\n",
    "X_test_loaded = pd.read_csv(\"../data/X_test.csv\", index_col=0)    # Use the first column as index\n",
    "y_test_loaded = pd.read_csv(\"../data/y_test.csv\", index_col=0)    # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the loaded datasets\n",
    "(X_train_loaded.head(), y_train_loaded.head(), X_test_loaded.head(), y_test_loaded.head())\n",
    "\n",
    "# Compare loaded data with original data\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=X['sex'], random_state=42\n",
    ")\n",
    "X_test = X_test_raw.dropna()\n",
    "y_test = y_test_raw.loc[X_test.index]\n",
    "X_train = X.drop(X_test.index)\n",
    "y_train = y.drop(y_test.index)\n",
    "\n",
    "# Check if the original and loaded training feature sets are equal\n",
    "X_train_comparison = X_train_loaded.equals(X_train)\n",
    "y_train_comparison = y_train_loaded.equals(y_train)\n",
    "\n",
    "# Check if the original and loaded test feature sets are equal\n",
    "X_test_comparison = X_test_loaded.equals(X_test)\n",
    "y_test_comparison = y_test_loaded.equals(y_test)\n",
    "\n",
    "# Create a summary of the comparisons\n",
    "comparison_results = {\n",
    "    'X_train_equal': X_train_comparison,\n",
    "    'y_train_equal': y_train_comparison,\n",
    "    'X_test_equal': X_test_comparison,\n",
    "    'y_test_equal': y_test_comparison,\n",
    "}\n",
    "\n",
    "# Print out the comparison results\n",
    "for key, value in comparison_results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# If any discrepancies found, print the first few mismatched rows\n",
    "if not X_train_comparison:\n",
    "    print(\"\\nMismatched rows in X_train:\")\n",
    "    print(X_train_loaded[X_train_loaded != X_train].dropna())\n",
    "\n",
    "if not y_train_comparison:\n",
    "    print(\"\\nMismatched values in y_train:\")\n",
    "    print(y_train_loaded[y_train_loaded != y_train].dropna())\n",
    "\n",
    "if not X_test_comparison:\n",
    "    print(\"\\nMismatched rows in X_test:\")\n",
    "    print(X_test_loaded[X_test_loaded != X_test].dropna())\n",
    "\n",
    "if not y_test_comparison:\n",
    "    print(\"\\nMismatched values in y_test:\")\n",
    "    print(y_test_loaded[y_test_loaded != y_test].dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bef505-e5af-4710-8219-f07dac262279",
   "metadata": {},
   "source": [
    "# Extension (SMOTE)\n",
    "\n",
    "Since we have unbalanced data, we may want to use a technique to balance the classes. One such method is SMOTE (synthetic minority oversampling technique) which uses nearest-neighbour methods to create synthetic minority samples. This is done to get balanced data.\n",
    "\n",
    "You may want to use this if you decide to tackle the imbalanced data. It's okay to not use this specific dataset and do your own SMOTE-ing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93cb41ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\megar\\anaconda3\\envs\\notebook\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\megar\\anaconda3\\envs\\notebook\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\megar\\anaconda3\\envs\\notebook\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\megar\\anaconda3\\envs\\notebook\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\megar\\anaconda3\\envs\\notebook\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95f08e83-beac-40ea-a6e6-198950354410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE-applied datasets (with restored categories) saved as '../data/X_train_smote.csv' and '../data/y_train_smote.csv'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize label encoders for each categorical column\n",
    "label_encoders = {}\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns  # Get categorical columns\n",
    "\n",
    "# Apply label encoding to categorical columns in X_train\n",
    "X_train_encoded = X_train.copy()  # Make a copy of the original data\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train_encoded[col])\n",
    "    label_encoders[col] = le  # Save the encoder for each column\n",
    "\n",
    "# Apply SMOTE to the label-encoded training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# After SMOTE, reverse the label encoding to restore original categorical values\n",
    "X_train_smote_restored = X_train_smote.copy()\n",
    "for col in categorical_columns:\n",
    "    le = label_encoders[col]  # Get the original label encoder for the column\n",
    "    X_train_smote_restored[col] = le.inverse_transform(X_train_smote_restored[col])\n",
    "\n",
    "# Save the SMOTE-applied datasets (with restored categorical values) to CSV files\n",
    "X_train_smote_restored.to_csv(\"../data/X_train_smote.csv\", index=True)  # Save features of SMOTE train set\n",
    "y_train_smote.to_csv(\"../data/y_train_smote.csv\", index=True)           # Save targets of SMOTE train set\n",
    "\n",
    "print(\"SMOTE-applied datasets (with restored categories) saved as '../data/X_train_smote.csv' and '../data/y_train_smote.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70deb9f3-65b1-46ac-a7b7-f677f34dbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_smote Loaded from CSV:\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  \n",
      "0          2174             0              40  United-States  \n",
      "1             0             0              13  United-States  \n",
      "2             0             0              40  United-States  \n",
      "3             0             0              40  United-States  \n",
      "4             0             0              40           Cuba  \n",
      "\n",
      "y_train_smote Loaded from CSV:\n",
      "  income\n",
      "0  <=50K\n",
      "1  <=50K\n",
      "2  <=50K\n",
      "3  <=50K\n",
      "4  <=50K\n"
     ]
    }
   ],
   "source": [
    "# Load the SMOTE-applied datasets\n",
    "X_train_smote_loaded = pd.read_csv(\"../data/X_train_smote.csv\", index_col=0)  # Use the first column as index\n",
    "y_train_smote_loaded = pd.read_csv(\"../data/y_train_smote.csv\", index_col=0)  # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"X_train_smote Loaded from CSV:\")\n",
    "print(X_train_smote_loaded.head())\n",
    "\n",
    "print(\"\\ny_train_smote Loaded from CSV:\")\n",
    "print(y_train_smote_loaded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ef682e4-20b4-4cbc-bcad-81473c53644b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(income\n",
       " <=50K     0.761628\n",
       " >50K      0.238372\n",
       " Name: proportion, dtype: float64,\n",
       " income\n",
       " <=50K     0.5\n",
       " >50K      0.5\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the target variable y_train before and after SMOTE\n",
    "y_train_distribution_before = y_train.value_counts(normalize=True)\n",
    "y_train_smote_distribution_after = y_train_smote.value_counts(normalize=True)\n",
    "\n",
    "y_train_distribution_before, y_train_smote_distribution_after"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
