{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da8c43d-a755-4c71-bddf-71e5244f6646",
   "metadata": {},
   "source": [
    "# Data Split\n",
    "\n",
    "We have decided to focus on the following question in our subsequent analysis:\n",
    "- How does the proportion of high income individuals vary across sex?\n",
    "\n",
    "In this document, we describe how the data is split. In particular, we stratify by sex. We ensure that the test data contains complete cases only to allow later comparison of different methods to deal with missingness. This is done in the following way:\n",
    "- We perform a train/test split on the data with no missing values. The split is stratified by sex. We keep the test set thus obtained. This set is ensured to have complete data.\n",
    "- We then take the remaining data (including the data which have missing values) to obtain the training set. \n",
    "\n",
    "This is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbee682",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "We begin by checking requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dde0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages to install:\n",
      "imblearn.over_sampling\n",
      "json\n",
      "numpy\n",
      "os\n",
      "pandas\n",
      "re\n",
      "sklearn.model_selection\n",
      "sklearn.preprocessing\n",
      "subprocess\n",
      "sys\n",
      "ucimlrepo\n",
      "\n",
      "Some packages like subprocess, os, re, sys, json are inbuilt so they don't need to be imported. We check and import the rest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'imblearn' is already installed.\n",
      "'numpy' is already installed.\n",
      "'pandas' is already installed.\n",
      "'ucimlrepo' is already installed.\n",
      "'scikit-learn' not found. Installing...\n",
      "\n",
      "All required packages are checked/installed.\n"
     ]
    }
   ],
   "source": [
    "######## REQUIREMENTS #################\n",
    "### PLEASE RUN THIS CELL FIRST ########\n",
    "#######################################\n",
    "\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_imports_from_code(code):\n",
    "    # Regex patterns to extract import statements\n",
    "    import_pattern = re.compile(r'^\\s*import\\s+([\\w\\.]+)', re.MULTILINE)\n",
    "    from_import_pattern = re.compile(r'^\\s*from\\s+([\\w\\.]+)\\s+import', re.MULTILINE)\n",
    "\n",
    "    # Find all matches for both patterns\n",
    "    imports = import_pattern.findall(code)\n",
    "    from_imports = from_import_pattern.findall(code)\n",
    "\n",
    "    # Return a set of unique imports\n",
    "    return set(imports + from_imports)\n",
    "\n",
    "def extract_imports_from_notebook(notebook_path):\n",
    "    # Open and read the Jupyter notebook\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    all_imports = set()\n",
    "\n",
    "    # Iterate through each cell in the notebook\n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            code = ''.join(cell['source'])  # Combine all lines of the code\n",
    "            imports_in_cell = extract_imports_from_code(code)\n",
    "            all_imports.update(imports_in_cell)\n",
    "\n",
    "    return all_imports\n",
    "\n",
    "notebook_path = '02.2-DataSplit.ipynb'  # Replace with your notebook file path\n",
    "packages_to_install = extract_imports_from_notebook(notebook_path)\n",
    "print(\"Packages to install:\")\n",
    "for package in sorted(packages_to_install):\n",
    "    print(package)\n",
    "print(\"\\nSome packages like subprocess, os, re, sys, json are inbuilt so they don't need to be imported. We check and import the rest\")\n",
    "\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of required packages (excluding built-in modules)\n",
    "required_packages = ['imblearn', 'numpy', 'pandas', 'ucimlrepo', 'scikit-learn']\n",
    "\n",
    "# Function to check and install packages\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "# Check and install required packages\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"'{package}' is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"'{package}' not found. Installing...\")\n",
    "        install(package)\n",
    "\n",
    "print(\"\\nAll required packages are checked/installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c07f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from sklearn.preprocessing import LabelEncoder  # For encoding categorical labels.\n",
    "from imblearn.over_sampling import SMOTE       # For synthetic data generation.\n",
    "import pandas as pd                             # For data manipulation and analysis.\n",
    "from ucimlrepo import fetch_ucirepo            # To fetch datasets from UCI repository.\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets into train/test sets.\n",
    "import numpy as np                             # For numerical operations.\n",
    "import os                                       # For operating system interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cb79a",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "We now do the required data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427a2870-efb7-47a1-9f22-b912ac0460fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLTTING PROCESS #######\n",
    "## STEP 1: LOAD THE DATA ##\n",
    "###########################\n",
    "\n",
    "# Fetch the Adult dataset from UCI ML repository\n",
    "adult = fetch_ucirepo(id=2)\n",
    "\n",
    "# Note this takes up to 20 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5269cf29-aebd-4329-a7cd-2185aed8cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\megar\\AppData\\Local\\Temp\\ipykernel_31784\\402134908.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.replace('?', np.nan, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of data by sex: overall data (before split), training data, test data.\n",
      "Overall sex proportion:\n",
      " sex\n",
      "Male      0.668482\n",
      "Female    0.331518\n",
      "Name: proportion, dtype: float64\n",
      "Training set sex proportion:\n",
      " sex\n",
      "Male      0.666466\n",
      "Female    0.333534\n",
      "Name: proportion, dtype: float64\n",
      "Test set sex proportion:\n",
      " sex\n",
      "Male      0.677327\n",
      "Female    0.322673\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## SPLTTING PROCESS ###########\n",
    "## STEP 2: PERFORM THE SPLIT ##\n",
    "###############################\n",
    "\n",
    "# Separate features and targets\n",
    "X = adult.data.features\n",
    "y = adult.data.targets\n",
    "\n",
    "# Replace '?' with NaN in X\n",
    "X.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Clean the target variable (income)\n",
    "y.loc[:, y.columns[0]] = y[y.columns[0]].replace({'<=50K.': '<=50K', '>50K.': '>50K'})\n",
    "\n",
    "# Ensure the split maintains the proportion of 'sex' in the test set\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=X['sex'], random_state=42\n",
    ")\n",
    "\n",
    "# Drop rows with missing data (NaN values) from X_test and ensure y_test is consistent\n",
    "X_test = X_test_raw.dropna()\n",
    "y_test = y_test_raw.loc[X_test.index]\n",
    "\n",
    "# Subtract X_test from the original dataset to get X_train\n",
    "X_train = X.drop(X_test.index)\n",
    "y_train = y.drop(y_test.index)\n",
    "\n",
    "# Display the proportion of 'sex' in the overall dataset, training, and test sets\n",
    "overall_sex_proportion = X['sex'].value_counts(normalize=True)\n",
    "train_sex_proportion = X_train['sex'].value_counts(normalize=True)\n",
    "test_sex_proportion = X_test['sex'].value_counts(normalize=True)\n",
    "\n",
    "# Print the proportions\n",
    "print(\"Proportion of data by sex: overall data (before split), training data, test data.\")\n",
    "print(\"Overall sex proportion:\\n\", overall_sex_proportion)\n",
    "print(\"Training set sex proportion:\\n\", train_sex_proportion)\n",
    "print(\"Test set sex proportion:\\n\", test_sex_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2163815",
   "metadata": {},
   "source": [
    "We see that the data has been stratified by sex correctly, since we see that the training set and test set have approximately the same sex proportion as the overall data. We next look at the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec1fd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values in each feature (training set):\n",
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "dtype: int64\n",
      "\n",
      "Number of missing values in each feature (test set):\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital-gain      0\n",
      "capital-loss      0\n",
      "hours-per-week    0\n",
      "native-country    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in X_train and X_test\n",
    "missing_in_train = X_train.isna().sum()\n",
    "missing_in_test = X_test.isna().sum()\n",
    "\n",
    "# Count the total number of missing values in each dataset\n",
    "total_missing_train = X_train.isna().sum().sum()\n",
    "total_missing_test = X_test.isna().sum().sum()\n",
    "\n",
    "# Print the number of missing data in each set\n",
    "print(\"\\nNumber of missing values in each feature (training set):\")\n",
    "print(missing_in_train)\n",
    "\n",
    "print(\"\\nNumber of missing values in each feature (test set):\")\n",
    "print(missing_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d566dc",
   "metadata": {},
   "source": [
    "This looks reasonable. We now write the data to csv files below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f43a031-484d-462c-abeb-dd00ce016d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Datasets saved as '../data/X_train.csv', '../data/y_train.csv', '../data/X_test.csv', and '../data/y_test.csv' with index.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 'data' directory in the parent directory if it doesn't exist\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "# Save X_train, y_train, X_test, and y_test to separate CSV files\n",
    "X_train.to_csv(\"../data/X_train.csv\", index=True)        # Save features of train set\n",
    "y_train.to_csv(\"../data/y_train.csv\", index=True)        # Save targets of train set\n",
    "X_test.to_csv(\"../data/X_test.csv\", index=True)          # Save features of test set\n",
    "y_test.to_csv(\"../data/y_test.csv\", index=True)          # Save targets of test set\n",
    "\n",
    "\"Datasets saved as '../data/X_train.csv', '../data/y_train.csv', '../data/X_test.csv', and '../data/y_test.csv' with index.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25abb09",
   "metadata": {},
   "source": [
    "This code can be used to load the data in subsequent analyses (and optionally check with the output to make sure it worked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5589c9-31eb-4ead-91fd-c1c31c17f39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   age         workclass  fnlwgt  education  education-num  \\\n",
       " 0   39         State-gov   77516  Bachelors             13   \n",
       " 1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       " 2   38           Private  215646    HS-grad              9   \n",
       " 3   53           Private  234721       11th              7   \n",
       " 4   28           Private  338409  Bachelors             13   \n",
       " \n",
       "        marital-status         occupation   relationship   race     sex  \\\n",
       " 0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       " 1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       " 2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       " 3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       " 4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       " \n",
       "    capital-gain  capital-loss  hours-per-week native-country  \n",
       " 0          2174             0              40  United-States  \n",
       " 1             0             0              13  United-States  \n",
       " 2             0             0              40  United-States  \n",
       " 3             0             0              40  United-States  \n",
       " 4             0             0              40           Cuba  ,\n",
       "   income\n",
       " 0  <=50K\n",
       " 1  <=50K\n",
       " 2  <=50K\n",
       " 3  <=50K\n",
       " 4  <=50K,\n",
       "        age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       " 20156   18   Private  271935       HS-grad              9       Never-married   \n",
       " 28772   67   Private  160456          11th              7             Widowed   \n",
       " 1732    26   Private  314177       HS-grad              9       Never-married   \n",
       " 38871   31   Private  176711       HS-grad              9       Never-married   \n",
       " 27566   56   Private  134286  Some-college             10  Married-civ-spouse   \n",
       " \n",
       "               occupation   relationship   race     sex  capital-gain  \\\n",
       " 20156  Machine-op-inspct      Own-child  White  Female             0   \n",
       " 28772      Other-service  Not-in-family  White  Female             0   \n",
       " 1732               Sales  Not-in-family  Black    Male             0   \n",
       " 38871       Craft-repair  Not-in-family  White    Male             0   \n",
       " 27566    Exec-managerial        Husband  White    Male             0   \n",
       " \n",
       "        capital-loss  hours-per-week native-country  \n",
       " 20156             0              40  United-States  \n",
       " 28772             0              40  United-States  \n",
       " 1732              0              40  United-States  \n",
       " 38871             0              40  United-States  \n",
       " 27566             0              45  United-States  ,\n",
       "       income\n",
       " 20156  <=50K\n",
       " 28772  <=50K\n",
       " 1732   <=50K\n",
       " 38871  <=50K\n",
       " 27566  <=50K)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved datasets from the CSV files\n",
    "X_train = pd.read_csv(\"../data/X_train.csv\", index_col=0)  # Use the first column as index\n",
    "y_train = pd.read_csv(\"../data/y_train.csv\", index_col=0)  # Use the first column as index\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\", index_col=0)    # Use the first column as index\n",
    "y_test = pd.read_csv(\"../data/y_test.csv\", index_col=0)    # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the loaded datasets\n",
    "(X_train.head(), y_train.head(), X_test.head(), y_test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb401c7b-e3cf-4cec-a558-7c8a8fbbd708",
   "metadata": {},
   "source": [
    "# Appendix: Checking\n",
    "\n",
    "Some checks were done to ensure that everything was correct. This appendix may be skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63da65a4-e6fc-4d03-a12c-9c6b2a4fd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_equal: True\n",
      "y_train_equal: True\n",
      "X_test_equal: True\n",
      "y_test_equal: True\n"
     ]
    }
   ],
   "source": [
    "# Load the saved datasets from the CSV files\n",
    "X_train_loaded = pd.read_csv(\"../data/X_train.csv\", index_col=0)  # Use the first column as index\n",
    "y_train_loaded = pd.read_csv(\"../data/y_train.csv\", index_col=0)  # Use the first column as index\n",
    "X_test_loaded = pd.read_csv(\"../data/X_test.csv\", index_col=0)    # Use the first column as index\n",
    "y_test_loaded = pd.read_csv(\"../data/y_test.csv\", index_col=0)    # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the loaded datasets\n",
    "(X_train_loaded.head(), y_train_loaded.head(), X_test_loaded.head(), y_test_loaded.head())\n",
    "\n",
    "# Compare loaded data with original data\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=X['sex'], random_state=42\n",
    ")\n",
    "X_test = X_test_raw.dropna()\n",
    "y_test = y_test_raw.loc[X_test.index]\n",
    "X_train = X.drop(X_test.index)\n",
    "y_train = y.drop(y_test.index)\n",
    "\n",
    "# Check if the original and loaded training feature sets are equal\n",
    "X_train_comparison = X_train_loaded.equals(X_train)\n",
    "y_train_comparison = y_train_loaded.equals(y_train)\n",
    "\n",
    "# Check if the original and loaded test feature sets are equal\n",
    "X_test_comparison = X_test_loaded.equals(X_test)\n",
    "y_test_comparison = y_test_loaded.equals(y_test)\n",
    "\n",
    "# Create a summary of the comparisons\n",
    "comparison_results = {\n",
    "    'X_train_equal': X_train_comparison,\n",
    "    'y_train_equal': y_train_comparison,\n",
    "    'X_test_equal': X_test_comparison,\n",
    "    'y_test_equal': y_test_comparison,\n",
    "}\n",
    "\n",
    "# Print out the comparison results\n",
    "for key, value in comparison_results.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# If any discrepancies found, print the first few mismatched rows\n",
    "if not X_train_comparison:\n",
    "    print(\"\\nMismatched rows in X_train:\")\n",
    "    print(X_train_loaded[X_train_loaded != X_train].dropna())\n",
    "\n",
    "if not y_train_comparison:\n",
    "    print(\"\\nMismatched values in y_train:\")\n",
    "    print(y_train_loaded[y_train_loaded != y_train].dropna())\n",
    "\n",
    "if not X_test_comparison:\n",
    "    print(\"\\nMismatched rows in X_test:\")\n",
    "    print(X_test_loaded[X_test_loaded != X_test].dropna())\n",
    "\n",
    "if not y_test_comparison:\n",
    "    print(\"\\nMismatched values in y_test:\")\n",
    "    print(y_test_loaded[y_test_loaded != y_test].dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bef505-e5af-4710-8219-f07dac262279",
   "metadata": {},
   "source": [
    "# Appendix: Extension (SMOTE)\n",
    "\n",
    "Since we have unbalanced data, we may want to use a technique to balance the classes. One such method is SMOTE (synthetic minority oversampling technique) which uses nearest-neighbour methods to create synthetic minority samples (see Section 5.2 for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f08e83-beac-40ea-a6e6-198950354410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE-applied datasets (with restored categories) saved as '../data/X_train_smote.csv' and '../data/y_train_smote.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize label encoders for each categorical column\n",
    "label_encoders = {}\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns  # Get categorical columns\n",
    "\n",
    "# Apply label encoding to categorical columns in X_train\n",
    "X_train_encoded = X_train.copy()  # Make a copy of the original data\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[col] = le.fit_transform(X_train_encoded[col])\n",
    "    label_encoders[col] = le  # Save the encoder for each column\n",
    "\n",
    "# Apply SMOTE to the label-encoded training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "# After SMOTE, reverse the label encoding to restore original categorical values\n",
    "X_train_smote_restored = X_train_smote.copy()\n",
    "for col in categorical_columns:\n",
    "    le = label_encoders[col]  # Get the original label encoder for the column\n",
    "    X_train_smote_restored[col] = le.inverse_transform(X_train_smote_restored[col])\n",
    "\n",
    "# Save the SMOTE-applied datasets (with restored categorical values) to CSV files\n",
    "X_train_smote_restored.to_csv(\"../data/X_train_smote.csv\", index=True)  # Save features of SMOTE train set\n",
    "y_train_smote.to_csv(\"../data/y_train_smote.csv\", index=True)           # Save targets of SMOTE train set\n",
    "\n",
    "print(\"SMOTE-applied datasets (with restored categories) saved as '../data/X_train_smote.csv' and '../data/y_train_smote.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70deb9f3-65b1-46ac-a7b7-f677f34dbe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_smote Loaded from CSV:\n",
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  \n",
      "0          2174             0              40  United-States  \n",
      "1             0             0              13  United-States  \n",
      "2             0             0              40  United-States  \n",
      "3             0             0              40  United-States  \n",
      "4             0             0              40           Cuba  \n",
      "\n",
      "y_train_smote Loaded from CSV:\n",
      "  income\n",
      "0  <=50K\n",
      "1  <=50K\n",
      "2  <=50K\n",
      "3  <=50K\n",
      "4  <=50K\n"
     ]
    }
   ],
   "source": [
    "# Load the SMOTE-applied datasets\n",
    "X_train_smote_loaded = pd.read_csv(\"../data/X_train_smote.csv\", index_col=0)  # Use the first column as index\n",
    "y_train_smote_loaded = pd.read_csv(\"../data/y_train_smote.csv\", index_col=0)  # Use the first column as index\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"X_train_smote Loaded from CSV:\")\n",
    "print(X_train_smote_loaded.head())\n",
    "\n",
    "print(\"\\ny_train_smote Loaded from CSV:\")\n",
    "print(y_train_smote_loaded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef682e4-20b4-4cbc-bcad-81473c53644b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(income\n",
       " <=50K     0.761628\n",
       " >50K      0.238372\n",
       " Name: proportion, dtype: float64,\n",
       " income\n",
       " <=50K     0.5\n",
       " >50K      0.5\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution of the target variable y_train before and after SMOTE\n",
    "y_train_distribution_before = y_train.value_counts(normalize=True)\n",
    "y_train_smote_distribution_after = y_train_smote.value_counts(normalize=True)\n",
    "\n",
    "y_train_distribution_before, y_train_smote_distribution_after"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
