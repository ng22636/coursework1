{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this group project, we explore a classification problem involving income data. The income data is sourced from the UCI Machine Learning Repository [1]. This data is obtained from a US Census, and contains information about whether the income of individuals exceed $50K or not. The project will involve exploring several models, such as discriminant analysis, decision trees and logistic regression. The model performance will be assessed on left-out test data. The left-out data is chosen to answer a particular scientific question. This question will be motivated by our EDA. \n",
    "\n",
    "We then explore several performance metrics, such as ROC curves, accuracy, precision and recall. We then select, test, and agree upon a performance metric to assess the models. The performance metric will be chosen such that it will lead to real-world generalisability. We will then compare the models with the chosen performance metric and reflect on the limitations and strengths of each method.\n",
    "\n",
    "The report is structured as follows.\n",
    "1. Section 1: We describe the scope of the project. \n",
    "2. Section 2: We perform exploratory data analysis with the aim of understanding the data and finding an interesting scientific question. We then split our data in a way such that we can investigate our chosen question.\n",
    "3. Section 3: We explore discriminant analysis, implementing LDA, QDA and regularised discriminant analysis. \n",
    "4. Section 4: We explore logistic regression. \n",
    "5. Section 5: We explore missingness in the context of decision trees. This covers methods such as surrogate splits, treating missingness as its own category and a complete-case analysis. We then explore imbalance, using SMOTE as a way to deal with imbalance. We then implement SMOTE together with a method to treat missingness. Concurrently, we explore ensembles such as random forests and gradient boosted trees. \n",
    "4. Section 6: We bring the results together, reflecting on each model's strengths and weaknesses.\n",
    "\n",
    "Throughout Sections 3 to 5, we explore several performance metrics. We agree to use a particular one in Section 6.\n",
    "\n",
    "# References\n",
    "\n",
    "[1] UCI Machine Learning Repository: https://archive.ics.uci.edu/dataset/2/adult"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
